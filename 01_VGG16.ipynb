{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 初心者ハンズオン\n",
    "# はじめての画像分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## ページ内目次\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#画像ファイルの読み込み\">画像ファイルの読み込み</a></li>\n",
    "<li><a href=\"#Kerasのインポート、VGG16モデルのロード\">Kerasのインポート、VGG16モデルのロード</a></li>\n",
    "<li><a href=\"#モデルを使って画像のクラスを予測する\">モデルを使って画像のクラスを予測する</a></li><li><a href=\"#Variableクラス中の数値データへのアクセス\">Variableクラス中の数値データへのアクセス</a></li>\n",
    "<li><a href=\"#複数画像をバッチ処理する\">複数画像をバッチ処理する</a></li>\n",
    "<li><a href=\"#model.predict()-が返す行列を理解する\">model.predict()が返す行列を理解する</a></li>\n",
    "<li><a href=\"#model.predict()-が返した確率をグラフ表示する\">model.predict()が返した確率をグラフ表示する</a></li>\n",
    "<li><a href=\"#ラベルリストの利用\">ラベルリストの利用</a></li>\n",
    "<li><a href=\"#Top-N-クラスの調査\">Top-N-クラスの調査</a></li>\n",
    "<li><a href=\"#Top-N-クラスの調査（クラスラベルとあわせて）\">Top-Nクラスの調査（クラスラベルとあわせて）</a></li>\n",
    "<li><a href=\"#matplotlib-による円グラフの表示\">matplotlibによる円グラフの表示</a></li>\n",
    "<li><a href=\"#さらなる演習\">さらなる演習</a></li>\n",
    "<li><a href=\"#様々な画像をまとめてロードする\">様々な画像をまとめてロードする</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Keras ハンズオンにようこそ！\n",
    "\n",
    "本ハンズオンでは、ディープラーニングや Keras フレームワークを利用したことがない方を対象として、ディープラーニングによる画像分類の方法をご紹介します。\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像に何が映っているか、深層学習によって推測させてみましょう。 Keras を使った場合、有名なネットワーク構造がいくつか、すぐに試せる状態になっています。ここでは、2015年に発表された VGG16 を使ってみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid; padding: 10px\">\n",
    "VGG16ネットワークは、224x224の画像を1000クラスに分類するためのネットワークです。\n",
    "\n",
    "<img src=\"_images/vgg16.png\">\n",
    "図: VGG16ネットワークの構造\n",
    "<p>\n",
    "Very Deep Convolutional Networks for Large-Scale Image Recognition<br>https://arxiv.org/abs/1409.1556\n",
    "\n",
    "<p>Keras では links.model.vision.vgg.VGG16Layers クラスが定義されています。 Keras 自体に学習済みデータは提供されていませんが、 Caffe 向けに公開されている学習済みモデルを読み込んで利用できるため、学習に時間をかけなくても試せます。\n",
    "\n",
    "https://github.com/chainer/chainer/blob/v2/chainer/links/model/vision/vgg.py\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この環境には<a href=\"00_sample_images.ipynb\">以下の画像</a>が準備されています。\n",
    "\n",
    "<table><tr style=\"align: center\"><td>airplane.jpg</td><td>cat.jpg</td><td>dog.jpg</td><td>dolphin.jpg</td><td>human_1.jpg</td><td>human_2.jpg</td><td>spider.jpg</td></tr>\n",
    "<tr><td><img src=\"airplane.jpg\" style=\"width: 96px\"></td><td><img src=\"cat.jpg\" style=\"width: 96px\"></td><td><img src=\"dog.jpg\"  style=\"width: 96px\"></td><td><img src=\"dolphin.jpg\" style=\"width: 96px\"></td><td><img src=\"human_1.jpg\" style=\"width: 96px\"></td><td><img src=\"human_2.jpg\" style=\"width: 96px\"></td><td><img src=\"spider.jpg\" style=\"width: 96px\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらの画像から1点選択し、読み込みます。下記の Notebook は cat.jpg を選択した選定で解説します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像ファイルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "img = image.load_img(\"cat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img) # 型を見てみましょう\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記ブロックを実行し、猫が表示されましたか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Kerasのインポート、VGG16モデルのロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kerasのインポート、訓練済みモデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "model = vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、 model には、 VGG16 と呼ばれる有名な画像分類ネットワークがロードされます。\n",
    "\n",
    "<div style=\"border: 1px solid; padding: 10px\">\n",
    "<tt>In[*]</tt> という表示がしばらく続くかもしれません。VGG16のデータファイルがない場合、インターネットからデータ(約500MB)をダウンロードし変換する必要があるため、辛抱強く待ってみてください。</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model オブジェクトが keras.engine.training.Model クラスであることを確認してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## モデルを使って画像のクラスを予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像 img をニューラルネットワークに入力し、出力 p を得る\n",
    "\n",
    "<div style=\"border: 1px solid; padding: 10px\">model.predict() は、２次元画像の配列を受け取ります。</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "# 画像データをVGG16用に編集\n",
    "img = img.resize((256,256)).crop((16,16,240,240))\n",
    "# 画像データを行列式へ変形\n",
    "d3_mtx = image.img_to_array(img)        # 3D-tensor(rows, cols, channels)\n",
    "d4_mtx = np.expand_dims(d3_mtx, axis=0) # 4D-tensor(samples, rows, cols, channels)\n",
    "\n",
    "d4_mtx = vgg16.preprocess_input(d4_mtx)   # 全体-平均値＆RGB->BGR\n",
    "p = model.predict(d4_mtx, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ model.predict() の実行には、いくらか時間がかかります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測結果（の生データ）を表示してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "たくさんの値が入った行列と型情報のTupleが見えるはずです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 数値データへのアクセス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kerasの予測結果は、chainerのVariableクラスと違って直接numpyのndarrayクラスに格納されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.__class__ # => numpy.ndarrayクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0, 1] # => (0, 1)の要素（numpy.float32クラス）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 複数画像をバッチ処理する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数の画像を連続で処理したい場合は、配列として画像を複数渡して、まとめて予測を得ることができます。この際、 model.predict() が返す配列の要素数は（イメージ数、 1000クラス）になります。\n",
    "\n",
    "1枚単位で画像を予測する場合と結果は一緒ですが、GPU搭載サーバーで短時間に多数の画像を予測したい場合、多数の画像をまとめて predict() することにより、システム全体のスループットが向上します。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1枚のみ処理する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_mtx = image.img_to_array(img)\n",
    "d4_mtx = np.expand_dims(d3_mtx, axis=0)\n",
    "p1 = model.predict(d4_mtx, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.shape # => (1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2枚処理する場合　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4_mtces = d4_mtx\n",
    "d4_mtces = np.append(d4_mtces, d4_mtx, axis=0)\n",
    "p2 = model.predict(d4_mtces, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.shape # 演習: 結果を予想してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3枚処理する場合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【演習】<br><br>\n",
    "３枚の画像を同時に model.predict() に渡して、期待どおりの要素数の配列が戻されることを確認してください。  \n",
    "個人マシンで行う場合は、メモリの使用量に気を付けてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演習：　３枚の画像を同時に model.predict() に渡してください\n",
    "d4_mtces = d4_mtx\n",
    "d4_mtces = np.append(d4_mtces, d4_mtx, axis=0)\n",
    "d4_mtces = np.append(d4_mtces, d4_mtx, axis=0)\n",
    "p3 = model.predict(d4_mtces)\n",
    "p3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## model.predict() が返す行列を理解する\n",
    "\n",
    "Python での配列操作に自身がない方は下記をお試しください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.random.random((10,10)) # 10行×10桁の配列を作成\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の行 (0行目)の10桁を返す\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の行 (0行目)の10桁から、4つめの要素を返す\n",
    "a[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記のとおり表記できる\n",
    "a[1, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 便利情報: 各行の4列目だけを取得する\n",
    "a[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## model.predict() が返した確率をグラフ表示する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid; padding: 10px\">以降、予測した最初の画像 (0行目) の内容について調査していきます。変数 d に p.data[0] を代入し、以降の操作は d に対して行います。</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以後、 p.data[0] にとしてアクセスする\n",
    "d = p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape # dの要素数を確認したい方はお試しください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d # 中身を見たい方はお試しください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d を棒グラフとして表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%matplotlib inline \n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(left=range(len(d)), height=d)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid; padding: 10px\">これは、0番目から999番目のクラスまで、そのクラスである確率の棒グラフです。200 ~ 400 の間にもっとも高いバーが見えているはずですが、この最も高い値がいくつめの要素か調べていきます。</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配列 d の中から最大値を探す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_label = np.argmax(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大値がある要素の番号を表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d[predicted_label] は d の中の最大値で、確率（0.0〜1.0）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[predicted_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.argmax(d) が 285  を返した場合、入力した画像 img は 285 番目のクラスに分類されたことを意味しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## ラベルリストの利用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力した画像は、 predicted_label 番目（285番目）のクラスである確率が高いことがわかりました。しかし、この 285 番目のクラスというのは何を指しているのでしょうか。\n",
    "\n",
    "（このモデルの学習時に利用された）クラスラベルリスト <a href=\"synset_words.txt\">synset_words.txt</a>  と照合することで、このクラスラベルが何を意味しているのかを調べます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = open(\"synset_words.txt\", \"r\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels の内容を確認する (1000個まで表示すると長いので、とりあえず最初の10個まで)\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力画像に対して最も高い確率を示したクラスのラベル文字列を表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_label 番目の要素を調べる\n",
    "labels[predicted_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行した結果、 Egyptian cat 、つまり、ニューラルネットワークは、この画像が Egyptian cat に分類した、ということになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Top-N クラスの調査"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid; padding: 10px\">返された値は「入力された画像が各クラスの値である確率」だと説明しました。また、最大値は 285番目の要素であることがわかりました。最大値に続く、大きな値を探してみましょう。</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率を昇順にソートして、最後の最大3件を表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(d)[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率を降順にソートして、最初の最大3件を表示（上記とは順序のみの違い）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(d, reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上位3クラスが占める確率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sorted(d, reverse=True)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Top-N クラスの調査（クラスラベルとあわせて）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid; padding: 10px\">このままではクラスラベルがなく、確率値が何に対応しているのかがわかりません。以下の操作で確率とクラスラベルをマージした上でソートしてみましょう。</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率とクラスラベルを組みわせたリストの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p2 = list(zip(p[0], labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成した組み合わせリストから Top 3 を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(p2, reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid; padding: 10px\">\n",
    "出力例\n",
    "\n",
    "<p>\n",
    "[<br>(0.52825135, 'n02124075 Egyptian cat\\n'), <br>\n",
    "   (0.11501167, 'n02123045 tabby, tabby cat\\n'), <br>\n",
    "   (0.052949127, 'n02123159 tiger cat\\n')<br>]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "【演習】<br><br>同様に、Top-10 クラスを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = list(zip(p[0], labels))\n",
    "sorted(p2, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## matplotlib による円グラフの表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid; padding: 10px\">降順にソートした確率一覧を matplotlib の円グラフにすることで、Top-Nクラスがどれぐらいの割合を占めるのかを視覚的に確認できます。</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d_sorted = sorted(d, key=lambda x:-x)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'font.size':15})\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.pie(d_sorted)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## さらなる演習\n",
    "\n",
    "【演習】<br>\n",
    "\n",
    "* ハンズオン環境に用意されている画像を model.predict() にわたし、各画像の予測クラス（１画像あたり1クラス）を表示してください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"00_sample_images.ipynb\">ハンズオン環境に存在する画像</a>をまとめて読み込みたい場合は、次のブロックを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_airplane = image.load_img(\"airplane.jpg\")\n",
    "img_cat = image.load_img(\"cat.jpg\")\n",
    "img_dog = image.load_img(\"dog.jpg\")\n",
    "img_dolphin = image.load_img(\"dolphin.jpg\")\n",
    "img_human1 = image.load_img(\"human_1.jpg\")\n",
    "img_human2 = image.load_img(\"human_2.jpg\")\n",
    "img_spider = image.load_img(\"spider.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演習\n",
    "img_airplane = img_airplane.resize((256,256)).crop((16,16,240,240))\n",
    "d3_air_mtx = image.img_to_array(img_airplane)\n",
    "d4_air_mtx = np.expand_dims(d3_air_mtx, axis=0)\n",
    "\n",
    "p = model.predict(d4_air_mtx, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
